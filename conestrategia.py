# -*- coding: utf-8 -*-
"""ConEstrategia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e_8XjLwPH0WbphKvb3GcfZ922LGi7esF

# Cargar las librerías necesarias
"""

import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.metrics import f1_score, roc_curve, roc_auc_score
import matplotlib.pyplot as plt
import joblib
import os

"""# Definir la función de preprocesamiento"""

def preprocess(df, target_col):
    EPS = 1e-7
    df = df[df['fare_amount'] > 0].reset_index(drop=True)
    df['tip_fraction'] = df['tip_amount'] / df['fare_amount']
    df[target_col] = df['tip_fraction'] > 0.2

    df['pickup_weekday'] = df['tpep_pickup_datetime'].dt.weekday
    df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour
    df['pickup_minute'] = df['tpep_pickup_datetime'].dt.minute
    df['work_hours'] = (
        (df['pickup_weekday'] >= 0) &
        (df['pickup_weekday'] <= 4) &
        (df['pickup_hour'] >= 8) &
        (df['pickup_hour'] <= 18)
    )
    df['trip_time'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.seconds
    df['trip_speed'] = df['trip_distance'] / (df['trip_time'] / 60 + EPS)

    features = [
        'pickup_weekday', 'pickup_hour', 'pickup_minute', 'work_hours',
        'passenger_count', 'trip_distance', 'trip_time', 'trip_speed',
        'PULocationID', 'DOLocationID', 'RatecodeID'
    ]
    df = df[features + [target_col]]
    df[features] = df[features].astype('float32').fillna(-1.0)
    df[target_col] = df[target_col].astype('int32')

    return df



# Crear directorio si no existe
os.makedirs('data/interim', exist_ok=True)

# Descargar los datos de enero 2020
data_url_jan = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-01.parquet'
df_jan = pd.read_parquet(data_url_jan)

# Preprocesar los datos
df_jan = preprocess(df_jan, 'high_tip')

# Guardar los datos preprocesados en un archivo CSV
df_jan.to_csv('data/interim/preprocessed_data_jan.csv', index=False)

target_col = 'high_tip'
features = [
    'pickup_weekday', 'pickup_hour', 'pickup_minute', 'work_hours',
    'passenger_count', 'trip_distance', 'trip_time', 'trip_speed',
    'PULocationID', 'DOLocationID', 'RatecodeID'
]

X_train = tf.convert_to_tensor(df_jan[features], dtype=tf.float32)
y_train = tf.convert_to_tensor(df_jan[target_col], dtype=tf.float32)

model = Sequential([
    Dense(128, activation='relu', input_shape=(len(features),)),
    Dense(64, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=2, batch_size=32)

train_preds = model.predict(X_train)
train_preds_binary = (train_preds > 0.5).astype(int)
f1_train = f1_score(y_train, train_preds_binary)
print(f'F1 Score en el conjunto de entrenamiento: {f1_train}')

months = ['2020-02', '2020-03', '2020-04', '2020-05']
f1_scores = []
auc_roc_scores = []
processed_months = []

plt.figure(figsize=(10, 6))

for month in months:
    try:
        data_url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{month}.parquet'
        taxi_month = pd.read_parquet(data_url)
        taxi_test = preprocess(taxi_month, target_col)

        X_test = tf.convert_to_tensor(taxi_test[features], dtype=tf.float32)
        y_test = tf.convert_to_tensor(taxi_test[target_col], dtype=tf.float32)

        test_preds = model.predict(X_test)
        test_preds_binary = (test_preds > 0.5).astype(int)
        f1_test = f1_score(y_test, test_preds_binary)
        f1_scores.append(f1_test)

        # Calcular AUC-ROC
        auc_roc = roc_auc_score(y_test, test_preds)
        auc_roc_scores.append(auc_roc)

        # Curva ROC
        fpr, tpr, _ = roc_curve(y_test, test_preds)
        plt.plot(fpr, tpr, label=f'{month} (AUC = {auc_roc:.2f})')

        processed_months.append(month)

    except Exception as e:
        print(f"Error procesando los datos para {month}: {e}")

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curvas ROC para Diferentes Meses')
plt.legend()
plt.show()

print(f"Processed Months: {processed_months}")
print(f"F1 Scores: {f1_scores}")
print(f"AUC-ROC Scores: {auc_roc_scores}")

if len(processed_months) != len(f1_scores) or len(processed_months) != len(auc_roc_scores):
    print("Error: Las longitudes de las listas no coinciden.")
else:
    processed_months.insert(0, '2020-01')
    f1_scores.insert(0, f1_train)
    auc_roc_scores.insert(0, roc_auc_score(y_train, train_preds))

    plt.figure(figsize=(14, 6))

    plt.subplot(1, 2, 1)
    plt.plot(processed_months, f1_scores, marker='o')
    plt.title('F1 Scores por Mes')
    plt.xlabel('Mes')
    plt.ylabel('F1 Score')
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(processed_months, auc_roc_scores, marker='o')
    plt.title('AUC-ROC por Mes')
    plt.xlabel('Mes')
    plt.ylabel('AUC-ROC')
    plt.grid(True)

    plt.tight_layout()
    plt.show()

    # Guardar los resultados
    results = {
        'months': processed_months,
        'f1_scores': f1_scores,
        'auc_roc_scores': auc_roc_scores
    }
    os.makedirs('models', exist_ok=True)
    joblib.dump(results, "models/model_results.joblib")
    print("Resultados guardados en 'models/model_results.joblib'")

